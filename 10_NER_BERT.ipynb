{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_NER_BERT",
      "provenance": [],
      "collapsed_sections": [
        "ILw_I2b2ncak",
        "7Sp1pxbXoBfY",
        "nYI2fSwfopke",
        "KeViPQxVpnXh",
        "QejbViYCtDvW",
        "EgOHcFIFxykL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeereshShringari/NLP-DHS-SRK/blob/master/10_NER_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILw_I2b2ncak",
        "colab_type": "text"
      },
      "source": [
        "### NER with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjtvAHAsnf02",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "\n",
        "* https://medium.com/@yingbiao/ner-with-bert-in-action-936ff275bc73"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mYBNEpsmGIM",
        "colab_type": "code",
        "outputId": "651e11ed-ff4f-45a8-d73e-c12e5eb6093f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeE0EodSmMsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "# case would be having upper case or lower case"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiUFaF97mdGq",
        "colab_type": "code",
        "outputId": "1d943428-2159-46e8-c319-b466dc017342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_path = \"/content/drive/My Drive/DHS2019_Workshop/GMB_NER/\"\n",
        "df = pd.read_csv(data_path + \"ner_dataset.csv\", encoding = \"ISO-8859-1\")\n",
        "df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1048575, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lp63aJjmfZ7",
        "colab_type": "code",
        "outputId": "1fdb47b5-ad07-40ca-b236-9fb10251beb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df = df.fillna(method='ffill')\n",
        "df.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg2JGUz5nGf9",
        "colab_type": "code",
        "outputId": "f51eb0c1-7be2-4d09-bb10-32258390c164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[\"Sentence #\"].nunique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47959"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J4u2nUNnNaH",
        "colab_type": "code",
        "outputId": "96f21195-c2cc-47a8-8fda-90457fecc879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[\"Word\"].nunique()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zay3Gl6unPu9",
        "colab_type": "code",
        "outputId": "b3a8fbda-dbc0-4124-80b1-77046f5d834c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "df[\"POS\"].unique()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NNS', 'IN', 'VBP', 'VBN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'CC',\n",
              "       'JJ', '.', 'VBD', 'WP', '``', 'CD', 'PRP', 'VBZ', 'POS', 'VBG',\n",
              "       'RB', ',', 'WRB', 'PRP$', 'MD', 'WDT', 'JJR', ':', 'JJS', 'WP$',\n",
              "       'RP', 'PDT', 'NNPS', 'EX', 'RBS', 'LRB', 'RRB', '$', 'RBR', ';',\n",
              "       'UH', 'FW'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkn37JHknSkn",
        "colab_type": "code",
        "outputId": "ea24890b-4123-4112-969e-1ff3be3085e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df[\"Tag\"].unique()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
              "       'I-eve', 'I-nat'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0_YNouunVVk",
        "colab_type": "code",
        "outputId": "6b81d089-a3bf-4598-f8b4-97ce29ce3beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "df[\"Tag\"].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        887908\n",
              "B-geo     37644\n",
              "B-tim     20333\n",
              "B-org     20143\n",
              "I-per     17251\n",
              "B-per     16990\n",
              "I-org     16784\n",
              "B-gpe     15870\n",
              "I-geo      7414\n",
              "I-tim      6528\n",
              "B-art       402\n",
              "B-eve       308\n",
              "I-art       297\n",
              "I-eve       253\n",
              "B-nat       201\n",
              "I-gpe       198\n",
              "I-nat        51\n",
              "Name: Tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sp1pxbXoBfY",
        "colab_type": "text"
      },
      "source": [
        "### Parse Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khlgNbAZnrbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "malKNT5goEEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getter = SentenceGetter(df)\n",
        "\n",
        "# Get sentence data\n",
        "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
        "\n",
        "# Get pos data\n",
        "poses = [[s[1] for s in sent] for sent in getter.sentences]\n",
        "\n",
        "# Get tag labels data\n",
        "labels = [[s[2] for s in sent] for sent in getter.sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKgfH8Y0og1P",
        "colab_type": "code",
        "outputId": "5cf4a944-9ddc-4dea-c28b-ee1b47547be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thousands',\n",
              " 'of',\n",
              " 'demonstrators',\n",
              " 'have',\n",
              " 'marched',\n",
              " 'through',\n",
              " 'London',\n",
              " 'to',\n",
              " 'protest',\n",
              " 'the',\n",
              " 'war',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'and',\n",
              " 'demand',\n",
              " 'the',\n",
              " 'withdrawal',\n",
              " 'of',\n",
              " 'British',\n",
              " 'troops',\n",
              " 'from',\n",
              " 'that',\n",
              " 'country',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZFDeH49oimS",
        "colab_type": "code",
        "outputId": "ac8fd4d1-416f-428e-f1e5-e4d14b363ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "poses[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NNS',\n",
              " 'IN',\n",
              " 'NNS',\n",
              " 'VBP',\n",
              " 'VBN',\n",
              " 'IN',\n",
              " 'NNP',\n",
              " 'TO',\n",
              " 'VB',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'NNP',\n",
              " 'CC',\n",
              " 'VB',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'JJ',\n",
              " 'NNS',\n",
              " 'IN',\n",
              " 'DT',\n",
              " 'NN',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrY_JvunolXp",
        "colab_type": "code",
        "outputId": "b25be903-4f9b-4cce-8596-e4604567b028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "labels[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-geo',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-geo',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-gpe',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYI2fSwfopke",
        "colab_type": "text"
      },
      "source": [
        "### Target Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e83PuX8Aon-Y",
        "colab_type": "code",
        "outputId": "aa1ff38c-a28b-4d6b-e6fa-ec24aeab916c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "tags_vals = list(set(df[\"Tag\"].values)) + ['X', '[CLS]', '[SEP]']\n",
        "tags_vals"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I-tim',\n",
              " 'B-geo',\n",
              " 'I-art',\n",
              " 'I-nat',\n",
              " 'B-eve',\n",
              " 'I-eve',\n",
              " 'O',\n",
              " 'I-org',\n",
              " 'I-per',\n",
              " 'I-gpe',\n",
              " 'I-geo',\n",
              " 'B-art',\n",
              " 'B-nat',\n",
              " 'B-org',\n",
              " 'B-per',\n",
              " 'B-gpe',\n",
              " 'B-tim',\n",
              " 'X',\n",
              " '[CLS]',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRkMO2W5pEqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag2idx={'B-art': 14,\n",
        " 'B-eve': 16,\n",
        " 'B-geo': 0,\n",
        " 'B-gpe': 13,\n",
        " 'B-nat': 12,\n",
        " 'B-org': 10,\n",
        " 'B-per': 4,\n",
        " 'B-tim': 2,\n",
        " 'I-art': 5,\n",
        " 'I-eve': 7,\n",
        " 'I-geo': 15,\n",
        " 'I-gpe': 8,\n",
        " 'I-nat': 11,\n",
        " 'I-org': 3,\n",
        " 'I-per': 6,\n",
        " 'I-tim': 1,\n",
        " 'X':17,\n",
        " 'O': 9,\n",
        " '[CLS]':18,\n",
        " '[SEP]':19}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDttXbjWpQTH",
        "colab_type": "code",
        "outputId": "f768ba08-cdf1-47ea-eb0c-7bec5a836cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "# Mapping index to name\n",
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}\n",
        "tag2name"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'B-geo',\n",
              " 1: 'I-tim',\n",
              " 2: 'B-tim',\n",
              " 3: 'I-org',\n",
              " 4: 'B-per',\n",
              " 5: 'I-art',\n",
              " 6: 'I-per',\n",
              " 7: 'I-eve',\n",
              " 8: 'I-gpe',\n",
              " 9: 'O',\n",
              " 10: 'B-org',\n",
              " 11: 'I-nat',\n",
              " 12: 'B-nat',\n",
              " 13: 'B-gpe',\n",
              " 14: 'B-art',\n",
              " 15: 'I-geo',\n",
              " 16: 'B-eve',\n",
              " 17: 'X',\n",
              " 18: '[CLS]',\n",
              " 19: '[SEP]'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeViPQxVpnXh",
        "colab_type": "text"
      },
      "source": [
        "### Creating Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIXYCFk_p5au",
        "colab_type": "code",
        "outputId": "7096bff4-44f1-4386-b62d-27d8d0a060bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.14)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.11.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.14 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.14)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkF0RHnap4Vu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "6e8a2553-d4dd-4d4d-cef3-5f3c6e40c7d9"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "\n",
        "from transformers import (WEIGHTS_NAME, \n",
        "                          BertConfig, BertForTokenClassification, BertTokenizer)\n",
        "from transformers import AdamW, WarmupLinearSchedule"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGZD5IA9pVCO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fb37aeb7-98a4-4777-b824-9586a8c37c15"
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForTokenClassification, BertTokenizer),\n",
        "}\n",
        "\n",
        "model_name = \"bert\"\n",
        "pretrained_model_name = \"bert-base-cased\"\n",
        "n_classes = len(tags_vals)\n",
        "\n",
        "config_class, model_class, tokenizer_class = MODEL_CLASSES[model_name]\n",
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_model_name, do_lower_case=False)\n",
        "model = model_class.from_pretrained(pretrained_model_name, num_labels=n_classes)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 86500.44B/s]\n",
            "100%|██████████| 213450/213450 [00:00<00:00, 388987.17B/s]\n",
            "100%|██████████| 435779157/435779157 [00:34<00:00, 12691393.31B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5THjunuXppX0",
        "colab_type": "code",
        "outputId": "3e4b9367-ff40-4b97-c48c-981841659017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "tokenized_texts = []\n",
        "word_piece_labels = []\n",
        "i_inc = 0\n",
        "for word_list,label in (zip(sentences,labels)):\n",
        "    temp_lable = []\n",
        "    temp_token = []\n",
        "    \n",
        "    # Add [CLS] at the front \n",
        "    temp_lable.append('[CLS]')\n",
        "    temp_token.append('[CLS]')\n",
        "    \n",
        "    for word,lab in zip(word_list,label):\n",
        "        token_list = tokenizer.tokenize(word)\n",
        "        for m,token in enumerate(token_list):\n",
        "            temp_token.append(token)\n",
        "            if m==0:\n",
        "                temp_lable.append(lab)\n",
        "            else:\n",
        "                temp_lable.append('X')  \n",
        "                \n",
        "    # Add [SEP] at the end\n",
        "    temp_lable.append('[SEP]')\n",
        "    temp_token.append('[SEP]')\n",
        "    \n",
        "    tokenized_texts.append(temp_token)\n",
        "    word_piece_labels.append(temp_lable)\n",
        "    \n",
        "    if 5 > i_inc:\n",
        "        print(\"No.%d,len:%d\"%(i_inc,len(temp_token)))\n",
        "        print(\"texts:%s\"%(\" \".join(temp_token)))\n",
        "        print(\"No.%d,len:%d\"%(i_inc,len(temp_lable)))\n",
        "        print(\"lables:%s\"%(\" \".join(temp_lable)))\n",
        "    i_inc +=1"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.0,len:28\n",
            "texts:[CLS] Thousands of demons ##tra ##tors have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country . [SEP]\n",
            "No.0,len:28\n",
            "lables:[CLS] O O O X X O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O [SEP]\n",
            "No.1,len:29\n",
            "texts:[CLS] Iranian officials say they expect to get access to sealed sensitive parts of the plant Wednesday , after an I ##A ##EA surveillance system begins functioning . [SEP]\n",
            "No.1,len:29\n",
            "lables:[CLS] B-gpe O O O O O O O O O O O O O O B-tim O O O B-org X X O O O O O [SEP]\n",
            "No.2,len:44\n",
            "texts:[CLS] He ##lic ##op ##ter guns ##hips Saturday pounded militant hide ##outs in the Or ##ak ##zai tribal region , where many Taliban militants are believed to have fled to avoid an earlier military offensive in nearby South W ##azi ##rist ##an . [SEP]\n",
            "No.2,len:44\n",
            "lables:[CLS] O X X X O X B-tim O O O X O O B-geo X X O O O O O B-org O O O O O O O O O O O O O O B-geo I-geo X X X O [SEP]\n",
            "No.3,len:16\n",
            "texts:[CLS] They left after a tense hour - long stand ##off with riot police . [SEP]\n",
            "No.3,len:16\n",
            "lables:[CLS] O O O O O O X X O X O O O O [SEP]\n",
            "No.4,len:47\n",
            "texts:[CLS] U . N . relief coordinator Jan E ##gel ##and said Sunday , U . S . , Indonesian and Australian military helicopters are ferry ##ing out food and supplies to remote areas of western Ace ##h province that ground crews can not reach . [SEP]\n",
            "No.4,len:47\n",
            "lables:[CLS] B-geo X X X O O B-per I-per X X O B-tim O B-geo X X X O B-gpe O B-gpe O O O O X O O O O O O O O O B-geo X O O O O O O O O [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zve_SSvXrgYL",
        "colab_type": "code",
        "outputId": "f409b9e7-034a-4047-8c0b-1d917561a724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_len = 50\n",
        "\n",
        "# Make text token into id\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "print(input_ids[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[  101 26159  1104  8568  4487  5067  1138  9639  1194  1498  1106  5641\n",
            "  1103  1594  1107  5008  1105  4555  1103 10602  1104  1418  2830  1121\n",
            "  1115  1583   119   102     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvdw_Tkerqw4",
        "colab_type": "code",
        "outputId": "03106584-dc84-497e-ca62-49f61eae192c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Make label into id, pad with \"O\" meaning others\n",
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in word_piece_labels],\n",
        "                     maxlen=max_len, value=tag2idx[\"O\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "print(tags[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18  9  9  9 17 17  9  9  9  0  9  9  9  9  9  0  9  9  9  9  9 13  9  9\n",
            "  9  9  9 19  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
            "  9  9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD0LSUq4rxSA",
        "colab_type": "code",
        "outputId": "c0c2669c-4012-431f-b6d0-80db6f365a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        }
      },
      "source": [
        "attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
        "attention_masks[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glGB6AOvsCIr",
        "colab_type": "code",
        "outputId": "73986b30-69cc-4a51-d55f-a7a11a8fe352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Since only one sentence, all the segment set to 0\n",
        "segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
        "print(segment_ids[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLS06kRysK_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "tr_inputs, val_inputs, tr_tags, val_tags, tr_masks, val_masks, tr_segs, val_segs = train_test_split(input_ids, tags,attention_masks,segment_ids, \n",
        "                                                            random_state=0, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEb0gmTLsX84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs, dtype=torch.long)\n",
        "val_inputs = torch.tensor(val_inputs, dtype=torch.long)\n",
        "tr_tags = torch.tensor(tr_tags, dtype=torch.long)\n",
        "val_tags = torch.tensor(val_tags, dtype=torch.long)\n",
        "tr_masks = torch.tensor(tr_masks, dtype=torch.long)\n",
        "val_masks = torch.tensor(val_masks, dtype=torch.long)\n",
        "tr_segs = torch.tensor(tr_segs, dtype=torch.long)\n",
        "val_segs = torch.tensor(val_segs, dtype=torch.long)\n",
        "\n",
        "batch_num = 10\n",
        "\n",
        "# Only set token embedding, attention embedding, no segment embedding\n",
        "train_data = data.TensorDataset(tr_inputs, tr_masks, tr_segs, tr_tags)\n",
        "train_sampler = data.RandomSampler(train_data)\n",
        "# Drop last can make batch training better for the last one\n",
        "train_dataloader = data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_num, drop_last=True)\n",
        "\n",
        "valid_data = data.TensorDataset(val_inputs, val_masks, val_segs, val_tags)\n",
        "valid_sampler = data.SequentialSampler(valid_data)\n",
        "valid_dataloader = data.DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QejbViYCtDvW",
        "colab_type": "text"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrVv_vais_ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "epochs = 1\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "num_train_optimization_steps = int( math.ceil(len(tr_inputs) / batch_num) / 1) * epochs\n",
        "# Fine tune model all layer parameters\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "      'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QaDAV9Itk36",
        "colab_type": "code",
        "outputId": "3f51d659-942e-4f84-d273-94b9cd6774a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from tqdm import tqdm,trange\n",
        "\n",
        "n_gpu=1\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "print(\"***** Running training *****\")\n",
        "print(\"  Num examples = %d\"%(len(tr_inputs)))\n",
        "print(\"  Batch size = %d\"%(batch_num))\n",
        "print(\"  Num steps = %d\"%(num_train_optimization_steps))\n",
        "for _ in trange(epochs,desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_segs, b_labels = batch\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=b_segs,\n",
        "        attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss, scores = outputs[:2]\n",
        "        if n_gpu>1:\n",
        "            # When multi gpu, average it\n",
        "            loss = loss.mean()\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        \n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 33571\n",
            "  Batch size = 10\n",
            "  Num steps = 3358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgOHcFIFxykL",
        "colab_type": "text"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeXanpDNuMFz",
        "colab_type": "code",
        "outputId": "500f93eb-41f8-46bf-adeb-5a62824de943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "print(\"***** Running evaluation *****\")\n",
        "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
        "print(\"  Batch size = {}\".format(batch_num))\n",
        "for step, batch in enumerate(valid_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    input_ids, input_mask, input_segs, label_ids = batch\n",
        "    \n",
        "#     if step > 2:\n",
        "#         break\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None,\n",
        "        attention_mask=input_mask,)\n",
        "        # For eval mode, the first result of outputs is logits\n",
        "        logits = outputs[0] \n",
        "    \n",
        "    # Get NER predict result\n",
        "    logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    \n",
        "    # Get NER true result\n",
        "    label_ids = label_ids.to('cpu').numpy()\n",
        "    \n",
        "    # Only predict the real word, mark=0, will not calculate\n",
        "    input_mask = input_mask.to('cpu').numpy()\n",
        "    \n",
        "    # Compare the valuable predict result\n",
        "    for i,mask in enumerate(input_mask):\n",
        "        # Real one\n",
        "        temp_1 = []\n",
        "        # Predict one\n",
        "        temp_2 = []\n",
        "        for j, m in enumerate(mask):\n",
        "            # Mark=0, meaning its a pad word, dont compare\n",
        "            if m:\n",
        "                if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
        "                    temp_1.append(tag2name[label_ids[i][j]])\n",
        "                    temp_2.append(tag2name[logits[i][j]])\n",
        "            else:\n",
        "                break\n",
        "        y_true.append(temp_1)\n",
        "        y_pred.append(temp_2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running evaluation *****\n",
            "  Num examples =14388\n",
            "  Batch size = 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUSHptk_uvPQ",
        "colab_type": "code",
        "outputId": "fbec8f59-ac62-4082-eb5e-46132ddfa6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "actuals = [item for sl in y_true for item in sl]\n",
        "preds = [item for sl in y_pred for item in sl]\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"f1 socre: %f\"%(metrics.f1_score(actuals, preds, average=\"macro\")))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 socre: 0.548077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA5Se8eDuxtQ",
        "colab_type": "code",
        "outputId": "b9216d97-a006-4e19-dfbc-88e5f392ef04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Accuracy score: %f\"%(metrics.accuracy_score(actuals, preds)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.969184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oxCOngku47k",
        "colab_type": "code",
        "outputId": "f2e8c5e6-ae34-4010-bb9a-c924f89bfff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "print(metrics.classification_report(actuals, preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.00      0.00      0.00       134\n",
            "       B-eve       0.70      0.23      0.35        98\n",
            "       B-geo       0.85      0.90      0.88     11313\n",
            "       B-gpe       0.96      0.93      0.94      4802\n",
            "       B-nat       0.83      0.21      0.34        71\n",
            "       B-org       0.80      0.70      0.75      5997\n",
            "       B-per       0.86      0.83      0.85      5120\n",
            "       B-tim       0.89      0.89      0.89      6242\n",
            "       I-art       0.00      0.00      0.00       100\n",
            "       I-eve       0.50      0.01      0.02        88\n",
            "       I-geo       0.84      0.76      0.80      2287\n",
            "       I-gpe       0.97      0.47      0.63        60\n",
            "       I-nat       0.00      0.00      0.00        21\n",
            "       I-org       0.83      0.76      0.80      5095\n",
            "       I-per       0.87      0.88      0.87      5160\n",
            "       I-tim       0.86      0.69      0.76      1996\n",
            "           O       0.99      1.00      0.99    264402\n",
            "           X       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97    312986\n",
            "   macro avg       0.65      0.51      0.55    312986\n",
            "weighted avg       0.97      0.97      0.97    312986\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}