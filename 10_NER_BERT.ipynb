{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_NER_BERT",
      "provenance": [],
      "collapsed_sections": [
        "ILw_I2b2ncak",
        "7Sp1pxbXoBfY",
        "nYI2fSwfopke",
        "KeViPQxVpnXh",
        "QejbViYCtDvW",
        "EgOHcFIFxykL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeereshShringari/NLP-DHS-SRK/blob/master/10_NER_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILw_I2b2ncak",
        "colab_type": "text"
      },
      "source": [
        "### NER with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjtvAHAsnf02",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "\n",
        "* https://medium.com/@yingbiao/ner-with-bert-in-action-936ff275bc73"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mYBNEpsmGIM",
        "colab_type": "code",
        "outputId": "8ce3c67d-4796-40b8-8c6e-ba9ff2e2cba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeE0EodSmMsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiUFaF97mdGq",
        "colab_type": "code",
        "outputId": "c99c720b-bd73-4d7d-e491-3e8121d2a46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_path = \"/content/drive/My Drive/DHS2019_Workshop/GMB_NER/\"\n",
        "df = pd.read_csv(data_path + \"ner_dataset.csv\", encoding = \"ISO-8859-1\")\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1048575, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lp63aJjmfZ7",
        "colab_type": "code",
        "outputId": "1a0a5b81-9012-49bf-e19a-37c44637d195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = df.fillna(method='ffill')\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg2JGUz5nGf9",
        "colab_type": "code",
        "outputId": "3aedf77f-01a2-46b7-d697-b5e2051fe97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[\"Sentence #\"].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47959"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J4u2nUNnNaH",
        "colab_type": "code",
        "outputId": "b42db021-a9fb-49b4-ec3e-046ce665b979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[\"Word\"].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zay3Gl6unPu9",
        "colab_type": "code",
        "outputId": "d7e2e54b-b453-463f-cd00-93962680e1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df[\"POS\"].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NNS', 'IN', 'VBP', 'VBN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'CC',\n",
              "       'JJ', '.', 'VBD', 'WP', '``', 'CD', 'PRP', 'VBZ', 'POS', 'VBG',\n",
              "       'RB', ',', 'WRB', 'PRP$', 'MD', 'WDT', 'JJR', ':', 'JJS', 'WP$',\n",
              "       'RP', 'PDT', 'NNPS', 'EX', 'RBS', 'LRB', 'RRB', '$', 'RBR', ';',\n",
              "       'UH', 'FW'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkn37JHknSkn",
        "colab_type": "code",
        "outputId": "58a2c687-258e-46ea-d7b4-71796bf8cb29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df[\"Tag\"].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
              "       'I-eve', 'I-nat'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0_YNouunVVk",
        "colab_type": "code",
        "outputId": "ee4aa9d1-77b6-4d9f-bee6-c9e96d5ed61b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "df[\"Tag\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        887908\n",
              "B-geo     37644\n",
              "B-tim     20333\n",
              "B-org     20143\n",
              "I-per     17251\n",
              "B-per     16990\n",
              "I-org     16784\n",
              "B-gpe     15870\n",
              "I-geo      7414\n",
              "I-tim      6528\n",
              "B-art       402\n",
              "B-eve       308\n",
              "I-art       297\n",
              "I-eve       253\n",
              "B-nat       201\n",
              "I-gpe       198\n",
              "I-nat        51\n",
              "Name: Tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sp1pxbXoBfY",
        "colab_type": "text"
      },
      "source": [
        "### Parse Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khlgNbAZnrbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "malKNT5goEEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getter = SentenceGetter(df)\n",
        "\n",
        "# Get sentence data\n",
        "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
        "\n",
        "# Get pos data\n",
        "poses = [[s[1] for s in sent] for sent in getter.sentences]\n",
        "\n",
        "# Get tag labels data\n",
        "labels = [[s[2] for s in sent] for sent in getter.sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKgfH8Y0og1P",
        "colab_type": "code",
        "outputId": "58db83e2-4c5f-414d-d851-75e133b5fa75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thousands',\n",
              " 'of',\n",
              " 'demonstrators',\n",
              " 'have',\n",
              " 'marched',\n",
              " 'through',\n",
              " 'London',\n",
              " 'to',\n",
              " 'protest',\n",
              " 'the',\n",
              " 'war',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'and',\n",
              " 'demand',\n",
              " 'the',\n",
              " 'withdrawal',\n",
              " 'of',\n",
              " 'British',\n",
              " 'troops',\n",
              " 'from',\n",
              " 'that',\n",
              " 'country',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZFDeH49oimS",
        "colab_type": "code",
        "outputId": "50d2a2b1-993e-4014-b3e3-430f3f17774c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "poses[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NNS',\n",
              " 'IN',\n",
              " 'NNS',\n",
              " 'VBP',\n",
              " 'VBN',\n",
              " 'IN',\n",
              " 'NNP',\n",
              " 'TO',\n",
              " 'VB',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'NNP',\n",
              " 'CC',\n",
              " 'VB',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'JJ',\n",
              " 'NNS',\n",
              " 'IN',\n",
              " 'DT',\n",
              " 'NN',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrY_JvunolXp",
        "colab_type": "code",
        "outputId": "1b002483-b0f6-42b6-a8b4-c231a213ae40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "labels[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-geo',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-geo',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-gpe',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYI2fSwfopke",
        "colab_type": "text"
      },
      "source": [
        "### Target Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e83PuX8Aon-Y",
        "colab_type": "code",
        "outputId": "21db3099-2b1d-4566-de27-78a457f46174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "tags_vals = list(set(df[\"Tag\"].values)) + ['X', '[CLS]', '[SEP]']\n",
        "tags_vals"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-geo',\n",
              " 'B-nat',\n",
              " 'I-org',\n",
              " 'B-tim',\n",
              " 'I-eve',\n",
              " 'B-art',\n",
              " 'I-art',\n",
              " 'I-nat',\n",
              " 'O',\n",
              " 'B-eve',\n",
              " 'B-gpe',\n",
              " 'I-per',\n",
              " 'B-per',\n",
              " 'I-gpe',\n",
              " 'I-tim',\n",
              " 'B-org',\n",
              " 'I-geo',\n",
              " 'X',\n",
              " '[CLS]',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRkMO2W5pEqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag2idx={'B-art': 14,\n",
        " 'B-eve': 16,\n",
        " 'B-geo': 0,\n",
        " 'B-gpe': 13,\n",
        " 'B-nat': 12,\n",
        " 'B-org': 10,\n",
        " 'B-per': 4,\n",
        " 'B-tim': 2,\n",
        " 'I-art': 5,\n",
        " 'I-eve': 7,\n",
        " 'I-geo': 15,\n",
        " 'I-gpe': 8,\n",
        " 'I-nat': 11,\n",
        " 'I-org': 3,\n",
        " 'I-per': 6,\n",
        " 'I-tim': 1,\n",
        " 'X':17,\n",
        " 'O': 9,\n",
        " '[CLS]':18,\n",
        " '[SEP]':19}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDttXbjWpQTH",
        "colab_type": "code",
        "outputId": "52d2fe23-4d3b-447e-c820-f047d9e47400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Mapping index to name\n",
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}\n",
        "tag2name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'B-geo',\n",
              " 1: 'I-tim',\n",
              " 2: 'B-tim',\n",
              " 3: 'I-org',\n",
              " 4: 'B-per',\n",
              " 5: 'I-art',\n",
              " 6: 'I-per',\n",
              " 7: 'I-eve',\n",
              " 8: 'I-gpe',\n",
              " 9: 'O',\n",
              " 10: 'B-org',\n",
              " 11: 'I-nat',\n",
              " 12: 'B-nat',\n",
              " 13: 'B-gpe',\n",
              " 14: 'B-art',\n",
              " 15: 'I-geo',\n",
              " 16: 'B-eve',\n",
              " 17: 'X',\n",
              " 18: '[CLS]',\n",
              " 19: '[SEP]'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeViPQxVpnXh",
        "colab_type": "text"
      },
      "source": [
        "### Creating Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIXYCFk_p5au",
        "colab_type": "code",
        "outputId": "bb8dbbd9-d9fe-4c0a-d455-adc58b1cf1ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n",
            "\r\u001b[K     |█                               | 10kB 29.7MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 62.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.14)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 54.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.14 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.14)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=5d914ab8c7028e1456d8e13a0d94df7edd33b2b4a528e818a7c6109a032f397d\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: regex, sentencepiece, sacremoses, transformers\n",
            "Successfully installed regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkF0RHnap4Vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "\n",
        "from transformers import (WEIGHTS_NAME, \n",
        "                          BertConfig, BertForTokenClassification, BertTokenizer)\n",
        "from transformers import AdamW, WarmupLinearSchedule"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGZD5IA9pVCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForTokenClassification, BertTokenizer),\n",
        "}\n",
        "\n",
        "model_name = \"bert\"\n",
        "pretrained_model_name = \"bert-base-cased\"\n",
        "n_classes = len(tags_vals)\n",
        "\n",
        "config_class, model_class, tokenizer_class = MODEL_CLASSES[model_name]\n",
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_model_name, do_lower_case=False)\n",
        "model = model_class.from_pretrained(pretrained_model_name, num_labels=n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5THjunuXppX0",
        "colab_type": "code",
        "outputId": "65327634-37f4-4a35-bf34-26173a42d130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "tokenized_texts = []\n",
        "word_piece_labels = []\n",
        "i_inc = 0\n",
        "for word_list,label in (zip(sentences,labels)):\n",
        "    temp_lable = []\n",
        "    temp_token = []\n",
        "    \n",
        "    # Add [CLS] at the front \n",
        "    temp_lable.append('[CLS]')\n",
        "    temp_token.append('[CLS]')\n",
        "    \n",
        "    for word,lab in zip(word_list,label):\n",
        "        token_list = tokenizer.tokenize(word)\n",
        "        for m,token in enumerate(token_list):\n",
        "            temp_token.append(token)\n",
        "            if m==0:\n",
        "                temp_lable.append(lab)\n",
        "            else:\n",
        "                temp_lable.append('X')  \n",
        "                \n",
        "    # Add [SEP] at the end\n",
        "    temp_lable.append('[SEP]')\n",
        "    temp_token.append('[SEP]')\n",
        "    \n",
        "    tokenized_texts.append(temp_token)\n",
        "    word_piece_labels.append(temp_lable)\n",
        "    \n",
        "    if 5 > i_inc:\n",
        "        print(\"No.%d,len:%d\"%(i_inc,len(temp_token)))\n",
        "        print(\"texts:%s\"%(\" \".join(temp_token)))\n",
        "        print(\"No.%d,len:%d\"%(i_inc,len(temp_lable)))\n",
        "        print(\"lables:%s\"%(\" \".join(temp_lable)))\n",
        "    i_inc +=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.0,len:28\n",
            "texts:[CLS] Thousands of demons ##tra ##tors have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country . [SEP]\n",
            "No.0,len:28\n",
            "lables:[CLS] O O O X X O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O [SEP]\n",
            "No.1,len:29\n",
            "texts:[CLS] Iranian officials say they expect to get access to sealed sensitive parts of the plant Wednesday , after an I ##A ##EA surveillance system begins functioning . [SEP]\n",
            "No.1,len:29\n",
            "lables:[CLS] B-gpe O O O O O O O O O O O O O O B-tim O O O B-org X X O O O O O [SEP]\n",
            "No.2,len:44\n",
            "texts:[CLS] He ##lic ##op ##ter guns ##hips Saturday pounded militant hide ##outs in the Or ##ak ##zai tribal region , where many Taliban militants are believed to have fled to avoid an earlier military offensive in nearby South W ##azi ##rist ##an . [SEP]\n",
            "No.2,len:44\n",
            "lables:[CLS] O X X X O X B-tim O O O X O O B-geo X X O O O O O B-org O O O O O O O O O O O O O O B-geo I-geo X X X O [SEP]\n",
            "No.3,len:16\n",
            "texts:[CLS] They left after a tense hour - long stand ##off with riot police . [SEP]\n",
            "No.3,len:16\n",
            "lables:[CLS] O O O O O O X X O X O O O O [SEP]\n",
            "No.4,len:47\n",
            "texts:[CLS] U . N . relief coordinator Jan E ##gel ##and said Sunday , U . S . , Indonesian and Australian military helicopters are ferry ##ing out food and supplies to remote areas of western Ace ##h province that ground crews can not reach . [SEP]\n",
            "No.4,len:47\n",
            "lables:[CLS] B-geo X X X O O B-per I-per X X O B-tim O B-geo X X X O B-gpe O B-gpe O O O O X O O O O O O O O O B-geo X O O O O O O O O [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zve_SSvXrgYL",
        "colab_type": "code",
        "outputId": "2f35e5eb-6bfb-482b-ef99-5c97b7e898da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_len = 50\n",
        "\n",
        "# Make text token into id\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "print(input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101 26159  1104  8568  4487  5067  1138  9639  1194  1498  1106  5641\n",
            "  1103  1594  1107  5008  1105  4555  1103 10602  1104  1418  2830  1121\n",
            "  1115  1583   119   102     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvdw_Tkerqw4",
        "colab_type": "code",
        "outputId": "6f8eb90c-a964-4418-93ec-ae6202d9e64d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Make label into id, pad with \"O\" meaning others\n",
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in word_piece_labels],\n",
        "                     maxlen=max_len, value=tag2idx[\"O\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "print(tags[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18  9  9  9 17 17  9  9  9  0  9  9  9  9  9  0  9  9  9  9  9 13  9  9\n",
            "  9  9  9 19  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
            "  9  9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD0LSUq4rxSA",
        "colab_type": "code",
        "outputId": "0bbb1497-28b6-4ca4-ea20-9baa45dd349f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
        "attention_masks[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glGB6AOvsCIr",
        "colab_type": "code",
        "outputId": "76f08a38-5e32-4ccc-eacb-30d4dc663c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Since only one sentence, all the segment set to 0\n",
        "segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
        "print(segment_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLS06kRysK_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "tr_inputs, val_inputs, tr_tags, val_tags, tr_masks, val_masks, tr_segs, val_segs = train_test_split(input_ids, tags,attention_masks,segment_ids, \n",
        "                                                            random_state=0, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEb0gmTLsX84",
        "colab_type": "code",
        "outputId": "16c1f5f9-f0ee-4fa6-9eb7-0737a885293e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs, dtype=torch.long)\n",
        "val_inputs = torch.tensor(val_inputs, dtype=torch.long)\n",
        "tr_tags = torch.tensor(tr_tags, dtype=torch.long)\n",
        "val_tags = torch.tensor(val_tags, dtype=torch.long)\n",
        "tr_masks = torch.tensor(tr_masks, dtype=torch.long)\n",
        "val_masks = torch.tensor(val_masks, dtype=torch.long)\n",
        "tr_segs = torch.tensor(tr_segs, dtype=torch.long)\n",
        "val_segs = torch.tensor(val_segs, dtype=torch.long)\n",
        "\n",
        "batch_num = 10\n",
        "\n",
        "# Only set token embedding, attention embedding, no segment embedding\n",
        "train_data = data.TensorDataset(tr_inputs, tr_masks, tr_segs, tr_tags)\n",
        "train_sampler = data.RandomSampler(train_data)\n",
        "# Drop last can make batch training better for the last one\n",
        "train_dataloader = data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_num, drop_last=True)\n",
        "\n",
        "valid_data = data.TensorDataset(val_inputs, val_masks, val_segs, val_tags)\n",
        "valid_sampler = data.SequentialSampler(valid_data)\n",
        "valid_dataloader = data.DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QejbViYCtDvW",
        "colab_type": "text"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrVv_vais_ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "epochs = 1\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "num_train_optimization_steps = int( math.ceil(len(tr_inputs) / batch_num) / 1) * epochs\n",
        "# Fine tune model all layer parameters\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "      'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QaDAV9Itk36",
        "colab_type": "code",
        "outputId": "f0a86877-e7fc-442a-9119-2138fc0356ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from tqdm import tqdm,trange\n",
        "\n",
        "n_gpu=1\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "print(\"***** Running training *****\")\n",
        "print(\"  Num examples = %d\"%(len(tr_inputs)))\n",
        "print(\"  Batch size = %d\"%(batch_num))\n",
        "print(\"  Num steps = %d\"%(num_train_optimization_steps))\n",
        "for _ in trange(epochs,desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_segs, b_labels = batch\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=b_segs,\n",
        "        attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss, scores = outputs[:2]\n",
        "        if n_gpu>1:\n",
        "            # When multi gpu, average it\n",
        "            loss = loss.mean()\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        \n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 33571\n",
            "  Batch size = 10\n",
            "  Num steps = 3358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch: 100%|██████████| 1/1 [04:54<00:00, 294.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.11815261553842846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgOHcFIFxykL",
        "colab_type": "text"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeXanpDNuMFz",
        "colab_type": "code",
        "outputId": "500f93eb-41f8-46bf-adeb-5a62824de943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "print(\"***** Running evaluation *****\")\n",
        "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
        "print(\"  Batch size = {}\".format(batch_num))\n",
        "for step, batch in enumerate(valid_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    input_ids, input_mask, input_segs, label_ids = batch\n",
        "    \n",
        "#     if step > 2:\n",
        "#         break\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None,\n",
        "        attention_mask=input_mask,)\n",
        "        # For eval mode, the first result of outputs is logits\n",
        "        logits = outputs[0] \n",
        "    \n",
        "    # Get NER predict result\n",
        "    logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    \n",
        "    # Get NER true result\n",
        "    label_ids = label_ids.to('cpu').numpy()\n",
        "    \n",
        "    # Only predict the real word, mark=0, will not calculate\n",
        "    input_mask = input_mask.to('cpu').numpy()\n",
        "    \n",
        "    # Compare the valuable predict result\n",
        "    for i,mask in enumerate(input_mask):\n",
        "        # Real one\n",
        "        temp_1 = []\n",
        "        # Predict one\n",
        "        temp_2 = []\n",
        "        for j, m in enumerate(mask):\n",
        "            # Mark=0, meaning its a pad word, dont compare\n",
        "            if m:\n",
        "                if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
        "                    temp_1.append(tag2name[label_ids[i][j]])\n",
        "                    temp_2.append(tag2name[logits[i][j]])\n",
        "            else:\n",
        "                break\n",
        "        y_true.append(temp_1)\n",
        "        y_pred.append(temp_2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running evaluation *****\n",
            "  Num examples =14388\n",
            "  Batch size = 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUSHptk_uvPQ",
        "colab_type": "code",
        "outputId": "fbec8f59-ac62-4082-eb5e-46132ddfa6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "actuals = [item for sl in y_true for item in sl]\n",
        "preds = [item for sl in y_pred for item in sl]\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"f1 socre: %f\"%(metrics.f1_score(actuals, preds, average=\"macro\")))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 socre: 0.548077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA5Se8eDuxtQ",
        "colab_type": "code",
        "outputId": "b9216d97-a006-4e19-dfbc-88e5f392ef04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Accuracy score: %f\"%(metrics.accuracy_score(actuals, preds)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.969184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oxCOngku47k",
        "colab_type": "code",
        "outputId": "f2e8c5e6-ae34-4010-bb9a-c924f89bfff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "print(metrics.classification_report(actuals, preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.00      0.00      0.00       134\n",
            "       B-eve       0.70      0.23      0.35        98\n",
            "       B-geo       0.85      0.90      0.88     11313\n",
            "       B-gpe       0.96      0.93      0.94      4802\n",
            "       B-nat       0.83      0.21      0.34        71\n",
            "       B-org       0.80      0.70      0.75      5997\n",
            "       B-per       0.86      0.83      0.85      5120\n",
            "       B-tim       0.89      0.89      0.89      6242\n",
            "       I-art       0.00      0.00      0.00       100\n",
            "       I-eve       0.50      0.01      0.02        88\n",
            "       I-geo       0.84      0.76      0.80      2287\n",
            "       I-gpe       0.97      0.47      0.63        60\n",
            "       I-nat       0.00      0.00      0.00        21\n",
            "       I-org       0.83      0.76      0.80      5095\n",
            "       I-per       0.87      0.88      0.87      5160\n",
            "       I-tim       0.86      0.69      0.76      1996\n",
            "           O       0.99      1.00      0.99    264402\n",
            "           X       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97    312986\n",
            "   macro avg       0.65      0.51      0.55    312986\n",
            "weighted avg       0.97      0.97      0.97    312986\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}